{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "## Installs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install torch torchvision captum\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports & loading models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import LayerGradCam\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerAttribution\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model = model.eval()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget - P .torch/models https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "labels_path = '.torch/models/imagenet_class_index.json'\n",
    "with open(labels_path) as json_data:\n",
    "    idx_to_labels = json.load(json_data)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_img = Image.open('path/cat.jpg')\n",
    "test_img_data = np.asarray(test_img)\n",
    "plt.imshow(test_img_data)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model expectation is 224x224 3-color image\n",
    "transform = transforms.Compose([\n",
    " transforms.Resize(256),\n",
    " transforms.CenterCrop(224), #crop the given tensor image at the center\n",
    " transforms.ToTensor()\n",
    "])\n",
    "# ImageNet normalization\n",
    "transform_normalize = transforms.Normalize(\n",
    "     mean=[0.485, 0.456, 0.406],\n",
    "     std=[0.229, 0.224, 0.225]\n",
    " )\n",
    "\n",
    "img = Image.open('path/cat.jpg')\n",
    "\n",
    "transformed_img = transform(img)\n",
    "\n",
    "input = transform_normalize(transformed_img)\n",
    "#unsqueeze returns a new tensor with a dimension of size one inserted at the #specified position.\n",
    "input = input.unsqueeze(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#call our model\n",
    "output = model(input)\n",
    "## applied softmax() function\n",
    "output = F.softmax(output, dim=1)\n",
    "#torch.topk returns the k largest elements of the given input tensor along a given #dimension.K here is 1\n",
    "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "pred_label_idx.squeeze_()\n",
    "#convert into a dictionnary of keyvalues pair the predict label, convert it #into a string to get the predicted label\n",
    "predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n",
    "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Attribution with Integrated Gradients"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')\n",
    "#Create IntegratedGradients object and get attributes\n",
    "integrated_gradients = IntegratedGradients(model)\n",
    "#Request the algorithm to assign our output target to\n",
    "attributions_ig = integrated_gradients.attribute(\n",
    "    input, target=pred_label_idx, n_steps=200)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#result visualization with custom colormap\n",
    "default_cmap = LinearSegmentedColormap.from_list('custom blue',\n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#000000'),\n",
    "                                                  (1, '#000000')], N=256)\n",
    "# use visualize_image_attr helper method for visualization to show the #original image for comparison\n",
    "_ = viz.visualize_image_attr(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1, 2, 0)),\n",
    "                             np.transpose(transformed_img.squeeze(\n",
    "                             ).cpu().detach().numpy(), (1, 2, 0)),\n",
    "                             method='heat_map',\n",
    "                             cmap=default_cmap,\n",
    "                             show_colorbar=True,\n",
    "                             sign='positive',\n",
    "                             outlier_perc=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "\n",
    "attributions_ig_nt = noise_tunnel.attribute(\n",
    "    input, nt_samples=10, nt_type='smoothgrad_sq', target=pred_label_idx)\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1, 2, 0)),\n",
    "                                      np.transpose(transformed_img.squeeze(\n",
    "                                      ).cpu().detach().numpy(), (1, 2, 0)),\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "gradient_shap = GradientShap(model)\n",
    "\n",
    "# Definition of baseline distribution of images\n",
    "rand_img_dist = torch.cat([input * 0, input * 1])\n",
    "\n",
    "attributions_gs = gradient_shap.attribute(input,\n",
    "                                          n_samples=50,\n",
    "                                          stdevs=0.0001,\n",
    "                                          baselines=rand_img_dist,\n",
    "                                          target=pred_label_idx)\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_gs.squeeze().cpu().detach().numpy(), (1, 2, 0)),\n",
    "                                      np.transpose(transformed_img.squeeze(\n",
    "                                      ).cpu().detach().numpy(), (1, 2, 0)),\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"absolute_value\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Layer Attribution with Layer GradCAM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "layer_gradcam = LayerGradCam(model, model.layer3[1].conv2)\n",
    "attributions_lgc = layer_gradcam.attribute(input, target=pred_label_idx)\n",
    "\n",
    "_ = viz.visualize_image_attr(attributions_lgc[0].cpu().permute(1,2,0).detach().numpy(),\n",
    "                             sign=\"all\",\n",
    "                             title=\"Layer 3 Block 1 Conv 2\")\n",
    "\n",
    "upsamp_attr_lgc = LayerAttribution.interpolate(attributions_lgc, input.shape[2:])\n",
    "\n",
    "print(attributions_lgc.shape)\n",
    "print(upsamp_attr_lgc.shape)\n",
    "print(input.shape)\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(upsamp_attr_lgc[0].cpu().permute(1,2,0).detach().numpy(),\n",
    "                                      transformed_img.permute(1,2,0).numpy(),\n",
    "                                      [\"original_image\",\"blended_heat_map\",\"masked_image\"],\n",
    "                                      [\"all\",\"positive\",\"positive\"],\n",
    "                                      show_colorbar=True,\n",
    "                                      titles=[\"Original\", \"Positive Attribution\", \"Masked\"],\n",
    "                                      fig_size=(18, 6))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Attribution with Occlusion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "occlusion = Occlusion(model)\n",
    "\n",
    "attributions_occ = occlusion.attribute(input,\n",
    "                                       target=pred_label_idx,\n",
    "                                       strides=(3, 8, 8),\n",
    "                                       sliding_window_shapes=(3, 15, 15),\n",
    "                                       baselines=0)\n",
    "\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze().cpu().detach().numpy(), (1, 2, 0)),\n",
    "                                      np.transpose(transformed_img.squeeze(\n",
    "                                      ).cpu().detach().numpy(), (1, 2, 0)),\n",
    "                                      [\"original_image\", \"heat_map\",\n",
    "                                          \"heat_map\", \"masked_image\"],\n",
    "                                      [\"all\", \"positive\", \"negative\", \"positive\"],\n",
    "                                      show_colorbar=True,\n",
    "                                      titles=[\"Original\", \"Positive Attribution\",\n",
    "                                              \"Negative Attribution\", \"Masked\"],\n",
    "                                      fig_size=(18, 6)\n",
    "                                      )\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}